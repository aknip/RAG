{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec889d86-0d16-477f-8b7f-be03d73ad957",
   "metadata": {},
   "source": [
    "# Advanced RAG with Chroma - Video Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee2f53-d88b-4f00-94a2-75a66d4149e9",
   "metadata": {},
   "source": [
    "Advanced RAG Techniques - Tutorial, Videos, by Andrew NG (Chroma DB)\n",
    "\n",
    "- https://medium.com/@LakshmiNarayana_U/advanced-rag-techniques-in-ai-retrieval-a-deep-dive-into-the-chroma-course-d8b06118cde3\n",
    "- Notebooks: https://github.com/dzlab/deeplearning.ai/tree/main/AdvancedRetrievalforAIwithChroma\n",
    "\n",
    "Welcome! Here's a few notes about the Chroma course notebooks.\n",
    " - A number of warnings pop up when running the notebooks. These are normal and can be ignored.\n",
    " - Some operations such as calling an LLM or an opeation using generated data return unpredictable results and so your notebook outputs may differ from the video.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4445fc2-5a99-4d86-bde0-cb2a2ef659f1",
   "metadata": {},
   "source": [
    "# Run from an virtualenv!\n",
    "```\n",
    "python3 -m virtualenv myenv \n",
    "source myenv/bin/activate \n",
    "# pip install notebook\n",
    "jupyter notebook\n",
    "\n",
    "# exit with:\n",
    "deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde4bd3-5f52-4a79-9364-1af672f4ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic >=2 causes compatibility issues with llama-index - that's why it's downgraded to 1.10.10\n",
    "%pip install llama-index llama-index-llms-openai langchain chardet lark sentence-transformers chromadb umap umap-learn matplotlib pydantic==1.10.10 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5536f0-651c-40e7-aa15-27ee0cda80b7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from helper_utils import word_wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff732a09-0976-4ebe-876a-c5859bb8af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from getpass import getpass\n",
    "import psutil\n",
    "import pprint\n",
    "from pprint import pprint as prettyprint\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195417a7-e827-4293-984a-99fe49ece21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Secrets (JSON string):  ········\n"
     ]
    }
   ],
   "source": [
    "IN_NOTEBOOK = any([\"jupyter-notebook\" in i for i in psutil.Process().parent().cmdline()])\n",
    "if IN_NOTEBOOK:\n",
    "  CREDS = json.loads(getpass(\"Secrets (JSON string): \"))\n",
    "  os.environ['CREDS'] = json.dumps(CREDS)\n",
    "  CREDS = json.loads(os.getenv('CREDS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007aa445-ee33-48e9-9ad7-29c58b0d4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v2']['credential'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c713b0a7-dacd-47a8-876b-fcfc22facc53",
   "metadata": {},
   "source": [
    "# 1. Simple RAG with LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3748b16d-d4a7-49c3-a48a-57dcfc42acd6",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Dear shareholders, colleagues, customers, and partners:  \n",
      "We are\n",
      "living through a period of historic economic, societal, and\n",
      "geopolitical change. The world in 2022 looks nothing like \n",
      "the world in\n",
      "2019. As I write this, inflation is at a 40 -year high, supply chains\n",
      "are stretched, and the war in Ukraine is \n",
      "ongoing. At the same time, we\n",
      "are entering a technological era with the potential to power awesome\n",
      "advancements \n",
      "across every sector of our economy and society. As the\n",
      "world’s largest softw\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"./data/microsoft_annual_report_2022.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]\n",
    "\n",
    "print(word_wrap(pdf_texts[0][:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "888a86f8-2fe2-4682-bdaf-c15129ed1a32",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 347\n",
      "\n",
      "increased, due in large part to significant global datacenter\n",
      "expansions and the growth in Xbox sales and usage. Despite \n",
      "these\n",
      "increases, we remain dedicated to achieving a net -zero future. We\n",
      "recognize that progress won’t always be linear, \n",
      "and the rate at which\n",
      "we can implement emissions reductions is dependent on many factors that\n",
      "can fluctuate over time.  \n",
      "On the path to becoming water positive, we\n",
      "invested in 21 water replenishment projects that are expected to\n",
      "generate \n",
      "over 1.3  million\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "\n",
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\\n\")\n",
    "print(word_wrap(character_split_texts[10][:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5665c695-22ea-4264-b1ac-5ba720b6d78b",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increased, due in large part to significant global datacenter\n",
      "expansions and the growth in xbox sales and usage. despite these\n",
      "increases, we remain dedicated to achieving a net - zero future. we\n",
      "recognize that progress won ’ t always be linear, and the rate at which\n",
      "we can implement emissions reductions is dependent on many factors that\n",
      "can fluctuate over time. on the path to becoming water positive, we\n",
      "invested in 21 water replenishment projects that are expected to\n",
      "generate over 1. 3 million cubic meters of volumetric benefits in nine\n",
      "water basins around the world. progress toward our zero waste\n",
      "commitment included diverting more than 15, 200 metric tons of solid\n",
      "waste otherwise headed to landfills and incinerators, as well as\n",
      "launching new circular centers to increase reuse and reduce e - waste\n",
      "at our datacenters. we contracted to protect over 17, 000 acres of land\n",
      "( 50 % more than the land we use to operate ), thus achieving our\n",
      "\n",
      "Total chunks: 349\n"
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "print(word_wrap(token_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a13d14-4484-46f0-8e67-277337f9d138",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "# embedding_function = OpenAIEmbeddings()\n",
    "print(embedding_function([token_split_texts[10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba6c8c5-9ce4-44d0-9223-6fdd77871f87",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "\n",
    "chroma_collection = chroma_client.create_collection(\n",
    "    \"microsoft_annual_report_2022\", \n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfdb54db-a442-423c-b006-c33a257cd7d7",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revenue, classified by significant product and service offerings, was\n",
      "as follows : ( in millions ) year ended june 30, 2022 2021 2020 server\n",
      "products and cloud services $ 67, 321 $ 52, 589 $ 41, 379 office\n",
      "products and cloud services 44, 862 39, 872 35, 316 windows 24, 761 22,\n",
      "488 21, 510 gaming 16, 230 15, 370 11, 575 linkedin 13, 816 10, 289 8,\n",
      "077 search and news advertising 11, 591 9, 267 8, 524 enterprise\n",
      "services 7, 407 6, 943 6, 409 devices 6, 991 6, 791 6, 457 other 5, 291\n",
      "4, 479 3, 768 total $ 198, 270 $ 168, 088 $ 143, 015 we have recast\n",
      "certain previously reported amounts in the table above to conform to\n",
      "the way we internally manage and monitor our business.\n",
      "\n",
      "\n",
      "74 note 13 — unearned revenue unearned revenue by segment was as\n",
      "follows : ( in millions ) june 30, 2022 2021 productivity and business\n",
      "processes $ 24, 558 $ 22, 120 intelligent cloud 19, 371 17, 710 more\n",
      "personal computing 4, 479 4, 311 total $ 48, 408 $ 44, 141 changes in\n",
      "unearned revenue were as follows : ( in millions ) year ended june 30,\n",
      "2022 balance, beginning of period $ 44, 141 deferral of revenue 110,\n",
      "455 recognition of unearned revenue ( 106, 188 ) balance, end of period\n",
      "$ 48, 408 revenue allocated to remaining performance obligations, which\n",
      "includes unearned revenue and amounts that will be invoiced and\n",
      "recognized as revenue in future periods, was $ 193 billion as of june\n",
      "30, 2022, of which $ 189 billion is related to the commercial portion\n",
      "of revenue. we expect to recognize approximately 45 % of this revenue\n",
      "over the next 12\n",
      "\n",
      "\n",
      "that are not sold separately. • we tested the mathematical accuracy of\n",
      "management ’ s calculations of revenue and the associated timing of\n",
      "revenue recognized in the financial statements.\n",
      "\n",
      "\n",
      "82 in addition, certain costs incurred at a corporate level that are\n",
      "identifiable and that benefit our segments are allocated to them. these\n",
      "allocated costs include legal, including settlements and fines,\n",
      "information technology, human resources, finance, excise taxes, field\n",
      "selling, shared facilities services, and customer service and support.\n",
      "each allocation is measured differently based on the specific facts and\n",
      "circumstances of the costs being allocated. segment revenue and\n",
      "operating income were as follows during the periods presented : ( in\n",
      "millions ) year ended june 30, 2022 2021 2020 revenue productivity and\n",
      "business processes $ 63, 364 $ 53, 915 $ 46, 398 intelligent cloud 75,\n",
      "251 60, 080 48, 366 more personal computing 59, 655 54, 093 48, 251\n",
      "total $ 198, 270 $ 168, 088 $ 143, 015 operating income\n",
      "\n",
      "\n",
      "47 financial statements and supplementary data income statements ( in\n",
      "millions, except per share amounts ) year ended june 30, 2022 2021 2020\n",
      "revenue : product $ 72, 732 $ 71, 074 $ 68, 041 service and other 125,\n",
      "538 97, 014 74, 974 total revenue 198, 270 168, 088 143, 015 cost of\n",
      "revenue : product 19, 064 18, 219 16, 017 service and other 43, 586 34,\n",
      "013 30, 061 total cost of revenue 62, 650 52, 232 46, 078 gross margin\n",
      "135, 620 115, 856 96, 937 research and development 24, 512 20, 716 19,\n",
      "269 sales and marketing 21, 825 20, 117 19, 598 general and\n",
      "administrative 5, 900 5, 107 5, 111 operating income 83, 383 69, 916\n",
      "52, 959 other income, net 333 1, 186 77 income before income taxes 83,\n",
      "716 71, 102 53, 036 provision for income taxes 10, 978 9, 831 8, 755\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the total revenue?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(word_wrap(document))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377a84aa-1d93-4e97-9b2d-d59c46355338",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba0ed8ca-6640-4c09-9cb3-9de5e7cf46dc",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "def rag(query, retrieved_documents, model=\"gpt-3.5-turbo\"):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28bac3a2-0d29-48dc-9b48-2d9313239a25",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total revenue for the year ended June 30, 2022 was $198,270\n",
      "million.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "\n",
    "print(word_wrap(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f2758-0f5a-49e5-b1fa-517b91324575",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0a3db75-dc6e-4979-b5ec-c8722fb2edcd",
   "metadata": {},
   "source": [
    "# 2. Visualize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b1c4fa6-fda2-47dd-9024-c8cd3f10add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/umap/umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "embeddings = chroma_collection.get(include=['embeddings'])['embeddings']\n",
    "umap_transform = umap.UMAP(random_state=0, transform_seed=0).fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96c96524-8fe9-432a-b872-09abc36335f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_embeddings(embeddings, umap_transform):\n",
    "    umap_embeddings = np.empty((len(embeddings),2))\n",
    "    for i, embedding in enumerate(tqdm(embeddings)): \n",
    "        umap_embeddings[i] = umap_transform.transform([embedding])\n",
    "    return umap_embeddings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058dce99-ca2b-473d-b467-9150f55a89cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████▋       | 287/349 [01:20<00:17,  3.51it/s]"
     ]
    }
   ],
   "source": [
    "projected_dataset_embeddings = project_embeddings(embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8aeeb9-a6e5-4451-b2fd-b17df2a823da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('Projected Embeddings')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c100d1d-e334-4ca4-b9fb-f763cd7ea4ed",
   "metadata": {},
   "source": [
    "## 2.1 Visualize query and results: Relevant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1105f1c-2c2f-4c4e-bbab-a58712893a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the total revenue?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=query, n_results=5, include=['documents', 'embeddings'])\n",
    "retrieved_documents = results['documents'][0]\n",
    "for document in results['documents'][0]:\n",
    "    print(word_wrap(document))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9a637-2616-489d-87de-668e48fe4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embedding_function([query])[0]\n",
    "retrieved_embeddings = results['embeddings'][0]\n",
    "\n",
    "projected_query_embedding = project_embeddings([query_embedding], umap_transform)\n",
    "projected_retrieved_embeddings = project_embeddings(retrieved_embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2cc60e-ebc5-4582-b8a1-a9785e7cf883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the projected query and retrieved documents in the embedding space\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "plt.scatter(projected_query_embedding[:, 0], projected_query_embedding[:, 1], s=150, marker='X', color='r')\n",
    "plt.scatter(projected_retrieved_embeddings[:, 0], projected_retrieved_embeddings[:, 1], s=100, facecolors='none', edgecolors='g')\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(f'{query}')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3069de8-996a-4c62-b14f-68340eb3ecd0",
   "metadata": {},
   "source": [
    "## 2.2 Visualize query and results: Wide spreaded / non relevant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee6f4c-1f0b-4a15-b451-27beee15a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What has Michael Jordan done for us lately?\"\n",
    "results = chroma_collection.query(query_texts=query, n_results=5, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in results['documents'][0]:\n",
    "    print(word_wrap(document))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b31ef-aa51-4e03-9cfe-667327b4e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embedding_function([query])[0]\n",
    "retrieved_embeddings = results['embeddings'][0]\n",
    "\n",
    "projected_query_embedding = project_embeddings([query_embedding], umap_transform)\n",
    "projected_retrieved_embeddings = project_embeddings(retrieved_embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a2c6a2-b66c-4539-9cd6-1c8a1aa49264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the projected query and retrieved documents in the embedding space\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "plt.scatter(projected_query_embedding[:, 0], projected_query_embedding[:, 1], s=150, marker='X', color='r')\n",
    "plt.scatter(projected_retrieved_embeddings[:, 0], projected_retrieved_embeddings[:, 1], s=100, facecolors='none', edgecolors='g')\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(f'{query}')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad80e8-1f96-4861-a698-5f54c5c24898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
